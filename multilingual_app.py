import random
import numpy as np
import torch
from chatterbox.mtl_tts import ChatterboxMultilingualTTS, SUPPORTED_LANGUAGES
import gradio as gr
import torchaudio as ta
import tempfile
import os

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ Running on device: {DEVICE}")

# --- Global Model Initialization ---
MODEL = None

LANGUAGE_CONFIG = {
    "ar": {
        "audio": "mtl_prompts/ar_prompts2.flac",
        "text": "ÙÙŠ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…Ø§Ø¶ÙŠØŒ ÙˆØµÙ„Ù†Ø§ Ø¥Ù„Ù‰ Ù…Ø¹Ù„Ù… Ø¬Ø¯ÙŠØ¯ Ø¨Ù…Ù„ÙŠØ§Ø±ÙŠÙ† Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø¹Ù„Ù‰ Ù‚Ù†Ø§ØªÙ†Ø§ Ø¹Ù„Ù‰ ÙŠÙˆØªÙŠÙˆØ¨."
    },
    "da": {
        "audio": "mtl_prompts/da_m1.flac",
        "text": "Sidste mÃ¥ned nÃ¥ede vi en ny milepÃ¦l med to milliarder visninger pÃ¥ vores YouTube-kanal."
    },
    "de": {
        "audio": "mtl_prompts/de_f1.flac",
        "text": "Letzten Monat haben wir einen neuen Meilenstein erreicht: zwei Milliarden Aufrufe auf unserem YouTube-Kanal."
    },
    "el": {
        "audio": "mtl_prompts/el_m.flac",
        "text": "Î¤Î¿Î½ Ï€ÎµÏÎ±ÏƒÎ¼Î­Î½Î¿ Î¼Î®Î½Î±, Ï†Ï„Î¬ÏƒÎ±Î¼Îµ ÏƒÎµ Î­Î½Î± Î½Î­Î¿ Î¿ÏÏŒÏƒÎ·Î¼Î¿ Î¼Îµ Î´ÏÎ¿ Î´Î¹ÏƒÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± Ï€ÏÎ¿Î²Î¿Î»Î­Ï‚ ÏƒÏ„Î¿ ÎºÎ±Î½Î¬Î»Î¹ Î¼Î±Ï‚ ÏƒÏ„Î¿ YouTube."
    },
    "en": {
        "audio": "mtl_prompts/en_f1.flac",
        "text": "Last month, we reached a new milestone with two billion views on our YouTube channel."
    },
    "es": {
        "audio": "mtl_prompts/es_f1.flac",
        "text": "El mes pasado alcanzamos un nuevo hito: dos mil millones de visualizaciones en nuestro canal de YouTube."
    },
    "fi": {
        "audio": "mtl_prompts/fi_m.flac",
        "text": "Viime kuussa saavutimme uuden virstanpylvÃ¤Ã¤n kahden miljardin katselukerran kanssa YouTube-kanavallamme."
    },
    "fr": {
        "audio": "mtl_prompts/fr_f1.flac",
        "text": "Le mois dernier, nous avons atteint un nouveau jalon avec deux milliards de vues sur notre chaÃ®ne YouTube."
    },
    "he": {
        "audio": "mtl_prompts/he_m1.flac",
        "text": "×‘×—×•×“×© ×©×¢×‘×¨ ×”×’×¢× ×• ×œ××‘×Ÿ ×“×¨×š ×—×“×©×” ×¢× ×©× ×™ ××™×œ×™××¨×“ ×¦×¤×™×•×ª ×‘×¢×¨×•×¥ ×”×™×•×˜×™×•×‘ ×©×œ× ×•."
    },
    "hi": {
        "audio": "mtl_prompts/hi_f1.flac",
        "text": "à¤ªà¤¿à¤›à¤²à¥‡ à¤®à¤¹à¥€à¤¨à¥‡ à¤¹à¤®à¤¨à¥‡ à¤à¤• à¤¨à¤¯à¤¾ à¤®à¥€à¤² à¤•à¤¾ à¤ªà¤¤à¥à¤¥à¤° à¤›à¥à¤†: à¤¹à¤®à¤¾à¤°à¥‡ YouTube à¤šà¥ˆà¤¨à¤² à¤ªà¤° à¤¦à¥‹ à¤…à¤°à¤¬ à¤µà¥à¤¯à¥‚à¤œà¤¼à¥¤"
    },
    "it": {
        "audio": "mtl_prompts/it_m1.flac",
        "text": "Il mese scorso abbiamo raggiunto un nuovo traguardo: due miliardi di visualizzazioni sul nostro canale YouTube."
    },
    "ja": {
        "audio": "mtl_prompts/ja_prompts1.flac",
        "text": "å…ˆæœˆã€ç§ãŸã¡ã®YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã§äºŒåå„„å›ã®å†ç”Ÿå›æ•°ã¨ã„ã†æ–°ãŸãªãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã«åˆ°é”ã—ã¾ã—ãŸã€‚"
    },
    "ko": {
        "audio": "mtl_prompts/ko_f.flac",
        "text": "ì§€ë‚œë‹¬ ìš°ë¦¬ëŠ” ìœ íŠœë¸Œ ì±„ë„ì—ì„œ ì´ì‹­ì–µ ì¡°íšŒìˆ˜ë¼ëŠ” ìƒˆë¡œìš´ ì´ì •í‘œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤."
    },
    "ms": {
        "audio": "mtl_prompts/ms_f.flac",
        "text": "Bulan lepas, kami mencapai pencapaian baru dengan dua bilion tontonan di saluran YouTube kami."
    },
    "nl": {
        "audio": "mtl_prompts/nl_m.flac",
        "text": "Vorige maand bereikten we een nieuwe mijlpaal met twee miljard weergaven op ons YouTube-kanaal."
    },
    "no": {
        "audio": "mtl_prompts/no_f1.flac",
        "text": "Forrige mÃ¥ned nÃ¥dde vi en ny milepÃ¦l med to milliarder visninger pÃ¥ YouTube-kanalen vÃ¥r."
    },
    "pl": {
        "audio": "mtl_prompts/pl_m.flac",
        "text": "W zeszÅ‚ym miesiÄ…cu osiÄ…gnÄ™liÅ›my nowy kamieÅ„ milowy z dwoma miliardami wyÅ›wietleÅ„ na naszym kanale YouTube."
    },
    "pt": {
        "audio": "mtl_prompts/pt_m1.flac",
        "text": "No mÃªs passado, alcanÃ§Ã¡mos um novo marco: dois mil milhÃµes de visualizaÃ§Ãµes no nosso canal do YouTube."
    },
    "ru": {
        "audio": "mtl_prompts/ru_m.flac",
        "text": "Ğ’ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğ¼ Ğ¼ĞµÑÑÑ†Ğµ Ğ¼Ñ‹ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ€ÑƒĞ±ĞµĞ¶Ğ°: Ğ´Ğ²Ğ° Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ° Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¾Ğ² Ğ½Ğ° Ğ½Ğ°ÑˆĞµĞ¼ YouTube-ĞºĞ°Ğ½Ğ°Ğ»Ğµ."
    },
    "sv": {
        "audio": "mtl_prompts/sv_f.flac",
        "text": "FÃ¶rra mÃ¥naden nÃ¥dde vi en ny milstolpe med tvÃ¥ miljarder visningar pÃ¥ vÃ¥r YouTube-kanal."
    },
    "sw": {
        "audio": "mtl_prompts/sw_m.flac",
        "text": "Mwezi uliopita, tulifika hatua mpya ya maoni ya bilioni mbili kweny kituo chetu cha YouTube."
    },
    "tr": {
        "audio": "mtl_prompts/tr_m.flac",
        "text": "GeÃ§en ay YouTube kanalÄ±mÄ±zda iki milyar gÃ¶rÃ¼ntÃ¼leme ile yeni bir dÃ¶nÃ¼m noktasÄ±na ulaÅŸtÄ±k."
    },
    "zh": {
        "audio": "mtl_prompts/zh_f2.flac",
        "text": "ä¸Šä¸ªæœˆï¼Œæˆ‘ä»¬è¾¾åˆ°äº†ä¸€ä¸ªæ–°çš„é‡Œç¨‹ç¢‘. æˆ‘ä»¬çš„YouTubeé¢‘é“è§‚çœ‹æ¬¡æ•°è¾¾åˆ°äº†äºŒåäº¿æ¬¡ï¼Œè¿™ç»å¯¹ä»¤äººéš¾ä»¥ç½®ä¿¡ã€‚"
    },
}

# --- UI Helpers ---
def default_audio_for_ui(lang: str) -> str | None:
    return LANGUAGE_CONFIG.get(lang, {}).get("audio")


def default_text_for_ui(lang: str) -> str:
    return LANGUAGE_CONFIG.get(lang, {}).get("text", "")


def get_supported_languages_display() -> str:
    """Generate a formatted display of all supported languages."""
    language_items = []
    for code, name in sorted(SUPPORTED_LANGUAGES.items()):
        language_items.append(f"**{name}** (`{code}`)")
    
    # Split into 2 lines
    mid = len(language_items) // 2
    line1 = " â€¢ ".join(language_items[:mid])
    line2 = " â€¢ ".join(language_items[mid:])
    
    return f"""
### ğŸŒ æ”¯æŒè¯­è¨€ï¼ˆå…± {len(SUPPORTED_LANGUAGES)} ç§ï¼‰
{line1}

{line2}
"""


def get_or_load_model():
    """Loads the ChatterboxMultilingualTTS model if it hasn't been loaded already,
    and ensures it's on the correct device."""
    global MODEL
    if MODEL is None:
        print("Model not loaded, initializing...")
        try:
            MODEL = ChatterboxMultilingualTTS.from_pretrained(DEVICE)
            if hasattr(MODEL, 'to') and str(MODEL.device) != DEVICE:
                MODEL.to(DEVICE)
            print(f"Model loaded successfully. Internal device: {getattr(MODEL, 'device', 'N/A')}")
        except Exception as e:
            print(f"Error loading model: {e}")
            raise
    return MODEL

# Defer model loading until first inference to speed up UI launch.
# If you want eager loading, set env var 'CHATTERBOX_EAGER_LOAD=1'.
if os.getenv("CHATTERBOX_EAGER_LOAD") == "1":
    try:
        get_or_load_model()
    except Exception as e:
        print(f"CRITICAL: Failed to load model on startup. Application may not function. Error: {e}")

def set_seed(seed: int):
    """Sets the random seed for reproducibility across torch, numpy, and random."""
    if seed is not None and seed > 0:
        torch.manual_seed(seed)
        if DEVICE == "cuda":
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
        random.seed(seed)
        np.random.seed(seed)
        print(f"Set random seed to: {seed}")
    
def resolve_audio_prompt(language_id: str, provided_path: str | None) -> str | None:
    """
    Decide which audio prompt to use:
    - If user provided a path (upload/mic/url), use it.
    - Else, fall back to language-specific default (if any).
    """
    if provided_path and str(provided_path).strip():
        return provided_path
    return LANGUAGE_CONFIG.get(language_id, {}).get("audio")


def generate_tts_audio(
    text_input: str,
    language_id: str,
    audio_prompt_path_input: str = None,
    exaggeration_input: float = 0.5,
    temperature_input: float = 0.8,
    seed_num_input: int = 0,
    cfgw_input: float = 0.5
) -> tuple[int, np.ndarray]:
    """
    Generate high-quality speech audio from text using Chatterbox Multilingual model with optional reference audio styling.
    Supported languages: English, French, German, Spanish, Italian, Portuguese, and Hindi.
    
    This tool synthesizes natural-sounding speech from input text. When a reference audio file 
    is provided, it captures the speaker's voice characteristics and speaking style. The generated audio 
    maintains the prosody, tone, and vocal qualities of the reference speaker, or uses default voice if no reference is provided.

    Args:
        text_input (str): The text to synthesize into speech (maximum 300 characters)
        language_id (str): The language code for synthesis (eg. en, fr, de, es, it, pt, hi)
        audio_prompt_path_input (str, optional): File path or URL to the reference audio file that defines the target voice style. Defaults to None.
        exaggeration_input (float, optional): Controls speech expressiveness (0.25-2.0, neutral=0.5, extreme values may be unstable). Defaults to 0.5.
        temperature_input (float, optional): Controls randomness in generation (0.05-5.0, higher=more varied). Defaults to 0.8.
        seed_num_input (int, optional): Random seed for reproducible results (0 for random generation). Defaults to 0.
        cfgw_input (float, optional): CFG/Pace weight controlling generation guidance (0.2-1.0). Defaults to 0.5, 0 for language transfer. 

    Returns:
        tuple[int, np.ndarray]: A tuple containing the sample rate (int) and the generated audio waveform (numpy.ndarray)
    """
    current_model = get_or_load_model()

    if current_model is None:
        raise RuntimeError("TTS model is not loaded.")

    if seed_num_input != 0:
        set_seed(int(seed_num_input))

    print(f"Generating audio for text: '{text_input[:50]}...'")
    
    # Handle optional audio prompt
    chosen_prompt = audio_prompt_path_input or default_audio_for_ui(language_id)

    generate_kwargs = {
        "exaggeration": exaggeration_input,
        "temperature": temperature_input,
        "cfg_weight": cfgw_input,
    }
    if chosen_prompt:
        generate_kwargs["audio_prompt_path"] = chosen_prompt
        print(f"Using audio prompt: {chosen_prompt}")
    else:
        print("No audio prompt provided; using default voice.")
        
    wav = current_model.generate(
        text_input[:300],  # Truncate text to max chars
        language_id=language_id,
        **generate_kwargs
    )
    print("Audio generation complete.")
    return (current_model.sr, wav.squeeze(0).numpy())

def save_audio_to_temp(sr: int, audio: np.ndarray) -> str:
    """Save audio array to a temporary WAV file and return its path."""
    tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
    tensor = torch.tensor(audio).unsqueeze(0)
    ta.save(tmp.name, tensor, sr)
    return tmp.name


def generate_and_save(
    text_input: str,
    language_id: str,
    audio_prompt_path_input: str = None,
    exaggeration_input: float = 0.5,
    temperature_input: float = 0.8,
    seed_num_input: int = 0,
    cfgw_input: float = 0.5,
):
    sr, audio = generate_tts_audio(
        text_input,
        language_id,
        audio_prompt_path_input,
        exaggeration_input,
        temperature_input,
        seed_num_input,
        cfgw_input,
    )
    path = save_audio_to_temp(sr, audio)
    return (sr, audio), path


def chat_generate(
    history: list,
    user_text: str,
    language_id: str,
    audio_prompt_path_input: str = None,
    exaggeration_input: float = 0.5,
    temperature_input: float = 0.8,
    seed_num_input: int = 0,
    cfgw_input: float = 0.5,
):
    audio_tuple, file_path = generate_and_save(
        user_text,
        language_id,
        audio_prompt_path_input,
        exaggeration_input,
        temperature_input,
        seed_num_input,
        cfgw_input,
    )
    lang_name = SUPPORTED_LANGUAGES.get(language_id, language_id)
    reply = f"âœ… å·²ç”Ÿæˆ {lang_name} è¯­éŸ³ã€‚è¯·åœ¨å³ä¾§è¯•å¬æˆ–ä¸‹è½½ã€‚"
    new_history = (history or []) + [(user_text, reply)]
    return new_history, audio_tuple, file_path

with gr.Blocks(
    theme=gr.themes.Soft(primary_hue="blue", secondary_hue="emerald", neutral_hue="gray"),
    css="""
    :root { --cb-primary: #3b82f6; --cb-secondary: #10b981; }
    #app-title { padding: 12px 16px; border-radius: 12px; background: linear-gradient(90deg, rgba(59,130,246,.12), rgba(16,185,129,.12)); }
    .section-card { border: 1px solid rgba(255,255,255,.08); border-radius: 12px; padding: 12px; background: rgba(255,255,255,.03); }
    .audio-note { font-size: 13px; opacity: .85; }
    #chatbot { border: 1px solid rgba(255,255,255,.08); }
    .generate-btn { height: 44px; font-weight: 600; }
    """
) as demo:
    gr.Markdown(
        """
        # ğŸŒ VoiceRepo æ”¯æŒå¤šè¯­è¨€çš„å£°éŸ³å…‹éš†ç³»ç»Ÿ
        ### é¢å‘ä¸­æ–‡ç”¨æˆ·çš„å¤šè¯­è¨€æ–‡æœ¬è½¬è¯­éŸ³ï¼Œæ”¯æŒå‚è€ƒéŸ³é¢‘é£æ ¼ä¸æƒ…ç»ªæ§åˆ¶ã€‚
        
        é¦–ä¸ªå·¥ç¨‹çº§çš„å¤šè¯­è¨€ TTS æ¨¡å‹ï¼Œæ”¯æŒ 23 ç§è¯­è¨€ï¼Œå¼€ç®±å³ç”¨ã€‚
        """,
        elem_id="app-title"
    )

    with gr.Tabs():
        with gr.Tab("ğŸ’¬ å¯¹è¯æ¨¡å¼"):
            initial_lang_chat = "fr"
            with gr.Row():
                with gr.Column(scale=1):
                    chat = gr.Chatbot(label="å¯¹è¯", type="tuples", height=400, elem_id="chatbot")
                    with gr.Group(elem_classes=["section-card"]):
                        chat_input = gr.Textbox(
                            value=default_text_for_ui(initial_lang_chat),
                            label="è¾“å…¥æ–‡æœ¬ï¼ˆæœ€å¤š 300 å­—ï¼‰",
                            max_lines=4,
                            placeholder="è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬â€¦"
                        )
                        chat_lang = gr.Dropdown(
                            choices=[(name, code) for code, name in ChatterboxMultilingualTTS.get_supported_languages().items()],
                            value=initial_lang_chat,
                            label="è¯­è¨€"
                        )
                        chat_ref = gr.Audio(
                            sources=["upload","microphone"],
                            type="filepath",
                            label="å‚è€ƒéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰",
                            value=None
                        )
                    gr.Markdown("ğŸ’¡ æç¤ºï¼šå‚è€ƒéŸ³é¢‘è¯­è¨€åº”ä¸é€‰æ‹©çš„è¯­è¨€ä¸€è‡´ï¼›è‹¥åšè¯­è¨€è¿ç§»å¯å°† CFG è®¾ä¸º 0ã€‚", elem_classes=["audio-note"]) 
                    with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                        exag_chat = gr.Slider(0.25, 2, step=.05, label="æƒ…ç»ª/å¼ºåº¦ï¼ˆNeutral=0.5ï¼‰", value=.5)
                        cfg_chat = gr.Slider(0.2, 1, step=.05, label="CFG/Pace", value=0.5)
                        seed_chat = gr.Number(value=0, label="éšæœºç§å­ï¼ˆ0 ä¸ºéšæœºï¼‰", precision=0)
                        temp_chat = gr.Slider(0.05, 5, step=.05, label="é‡‡æ ·æ¸©åº¦ï¼ˆTemperatureï¼‰", value=.8)
                    with gr.Row():
                        send_btn = gr.Button("å‘é€å¹¶ç”Ÿæˆ", variant="primary", elem_classes=["generate-btn"]) 
                        clear_chat_btn = gr.Button("æ¸…ç©ºå¯¹è¯")
                with gr.Column(scale=1):
                    audio_out_chat = gr.Audio(label="è¾“å‡ºéŸ³é¢‘", interactive=False)
                    download_btn_chat = gr.DownloadButton(label="â¬‡ï¸ ä¸‹è½½éŸ³é¢‘", value=None)
            def on_language_change(lang, current_ref, current_text):
                return default_audio_for_ui(lang), default_text_for_ui(lang)
            chat_lang.change(
                fn=on_language_change,
                inputs=[chat_lang, chat_ref, chat_input],
                outputs=[chat_ref, chat_input],
                show_progress=False
            )
            send_btn.click(
                fn=chat_generate,
                inputs=[chat, chat_input, chat_lang, chat_ref, exag_chat, temp_chat, seed_chat, cfg_chat],
                outputs=[chat, audio_out_chat, download_btn_chat]
            )
            def _clear_chat():
                return [], None, None
            clear_chat_btn.click(fn=_clear_chat, inputs=[], outputs=[chat, audio_out_chat, download_btn_chat])

        with gr.Tab("ğŸ™ï¸ ç”Ÿæˆæ¨¡å¼"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### è¾“å…¥è®¾ç½®")
                    with gr.Group(elem_classes=["section-card"]):
                        initial_lang = "fr"
                        text = gr.Textbox(
                            value=default_text_for_ui(initial_lang),
                            label="åˆæˆæ–‡æœ¬ï¼ˆæœ€å¤š 300 å­—ï¼‰",
                            max_lines=5
                        )
                        language_id = gr.Dropdown(
                            choices=[(name, code) for code, name in ChatterboxMultilingualTTS.get_supported_languages().items()],
                            value=initial_lang,
                            label="è¯­è¨€"
                        )
                        ref_wav = gr.Audio(
                            sources=["upload","microphone"],
                            type="filepath",
                            label="å‚è€ƒéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰",
                            value=None
                        )
                    gr.Markdown("ğŸ’¡ æç¤ºï¼šå‚è€ƒéŸ³é¢‘æœ€å¥½ä¸ç›®æ ‡è¯­è¨€ç›¸åŒï¼›åšè¯­è¨€è¿ç§»æ—¶å¯å°† CFG è®¾ä¸º 0ã€‚", elem_classes=["audio-note"]) 
                    gr.Markdown("### è¯­éŸ³å‚æ•°")
                    with gr.Group(elem_classes=["section-card"]):
                        exaggeration = gr.Slider(0.25, 2, step=.05, label="æƒ…ç»ª/å¼ºåº¦ï¼ˆNeutral = 0.5ï¼Œè¿‡é«˜å¯èƒ½ä¸ç¨³å®šï¼‰", value=.5)
                        cfg_weight = gr.Slider(0.2, 1, step=.05, label="CFG/Pace", value=0.5)
                    with gr.Accordion("é«˜çº§ç”Ÿæˆé€‰é¡¹", open=False):
                        seed_num = gr.Number(value=0, label="éšæœºç§å­ï¼ˆ0 ä¸ºéšæœºï¼‰", precision=0)
                        temp = gr.Slider(0.05, 5, step=.05, label="é‡‡æ ·æ¸©åº¦ï¼ˆTemperatureï¼‰", value=.8)
                    with gr.Row():
                        run_btn = gr.Button("ç”Ÿæˆè¯­éŸ³", variant="primary", elem_classes=["generate-btn"]) 
                        clear_btn = gr.Button("æ¸…ç©ºå‚æ•°")
                with gr.Column(scale=1):
                    gr.Markdown("### è¾“å‡º")
                    with gr.Group(elem_classes=["section-card"]):
                        audio_output = gr.Audio(label="è¾“å‡ºéŸ³é¢‘", interactive=False)
                        download_btn = gr.DownloadButton(label="â¬‡ï¸ ä¸‹è½½éŸ³é¢‘", value=None)
                    gr.Markdown("### ä½¿ç”¨æç¤º")
                    gr.Markdown("""
                    - å‚è€ƒéŸ³é¢‘è¶Šæ¸…æ™°ï¼Œå…‹éš†æ•ˆæœè¶Šå¥½
                    - æå‡ exaggeration å¢å¼ºæƒ…æ„Ÿè¡¨è¾¾
                    - é™ä½ CFG/Pace å¯èƒ½æ›´è‡ªç„¶ä½†å…‹éš†åº¦æ›´ä½
                    - å›ºå®šéšæœºç§å­ä»¥ä¾¿å¤ç°
                    """)
            def on_language_change(lang, current_ref, current_text):
                return default_audio_for_ui(lang), default_text_for_ui(lang)
            language_id.change(
                fn=on_language_change,
                inputs=[language_id, ref_wav, text],
                outputs=[ref_wav, text],
                show_progress=False
            )
            run_btn.click(
                fn=generate_and_save,
                inputs=[text, language_id, ref_wav, exaggeration, temp, seed_num, cfg_weight],
                outputs=[audio_output, download_btn]
            )
            def _clear_params():
                return default_audio_for_ui(initial_lang), default_text_for_ui(initial_lang), 0, 0.8
            clear_btn.click(fn=_clear_params, inputs=[], outputs=[ref_wav, text, seed_num, temp])

        with gr.Tab("ğŸ“š è¯­è¨€ä¸ç¤ºä¾‹"):
            gr.Markdown(get_supported_languages_display())
            examples = [[default_text_for_ui(code), code, None] for code in SUPPORTED_LANGUAGES.keys()]
            gr.Examples(
                examples=examples,
                inputs=[text, language_id, ref_wav],
                label="å¿«é€Ÿç¤ºä¾‹ï¼šç‚¹å‡»å¡«å……è¾“å…¥",
                examples_per_page=12
            )

        with gr.Tab("ğŸ“˜ å…³äº"):
            gr.Markdown(
                """
                # ğŸ“˜ å…³äº VoiceRepoï¼Ÿ
                
                ## ğŸ¯ ä»€ä¹ˆæ˜¯ VoiceRepoï¼Ÿ
                VoiceRepo åŸºäº Resemble AI å¼€æºçš„å·¥ç¨‹çº§å¤šè¯­è¨€ TTS æ¨¡å‹å¼€å‘ï¼Œ
                æ”¯æŒ 23 ç§è¯­è¨€ã€‚åœ¨å¤šé¡¹è¯„æµ‹ä¸­è¶…è¿‡å…¶ä»–é—­æºç³»ç»Ÿï¼Œå¹¶åœ¨ç”¨æˆ·ä¸»è§‚åå¥½æµ‹è¯•ä¸­è·å¾—æ›´é«˜è®¤å¯ã€‚
                
                ## ğŸ”§ ä¸»è¦ç‰¹æ€§
                - å¤šè¯­è¨€æ”¯æŒï¼š23 ç§è¯­è¨€ï¼Œé›¶æ ·æœ¬å£°éŸ³å…‹éš†
                - æƒ…ç»ª/å¼ºåº¦æ§åˆ¶ï¼šé€šè¿‡ exaggeration å‚æ•°è°ƒèŠ‚è¡¨è¾¾åŠ›åº¦
                - å£°éŸ³è½¬æ¢ï¼šå¯æä¾›å‚è€ƒéŸ³é¢‘è¿›è¡Œé£æ ¼è¿ç§»
                - è´£ä»»æœºåˆ¶ï¼šå†…ç½®ç¥ç»æ°´å°ï¼Œæ”¯æŒåˆè§„ä½¿ç”¨
                
                ## ğŸš€ æŠ€æœ¯ç»†èŠ‚
                - 5 äº¿å‚æ•°çš„ Llama ç³»å£°å­¦æ¨¡å‹ï¼ˆT3ï¼‰
                - åŸºäº Flow Matching çš„è§£ç å™¨ï¼ˆMatchaï¼‰
                - é¢å‘å¯¹é½çš„æ¨ç†ä»¥æå‡ç¨³å®šæ€§
                - CUDA åŠ é€Ÿæ¨ç†
                
                ## ğŸ“– ä½¿ç”¨æ–¹æ³•
                1. ä»ä¸‹æ‹‰èœå•é€‰æ‹©è¯­è¨€
                2. åœ¨æ–‡æœ¬æ¡†è¾“å…¥æˆ–ä¿®æ”¹è¦åˆæˆçš„æ–‡æœ¬
                3. å¯é€‰ï¼šä¸Šä¼ æˆ–å½•åˆ¶å‚è€ƒéŸ³é¢‘ä»¥å…‹éš†ç›®æ ‡å£°éŸ³é£æ ¼
                4. æ ¹æ®éœ€è¦è°ƒæ•´é«˜çº§å‚æ•°
                5. ç‚¹å‡»â€œç”Ÿæˆè¯­éŸ³â€å¼€å§‹åˆæˆ
                
                ## âš ï¸ æ³¨æ„äº‹é¡¹
                - å‚è€ƒéŸ³é¢‘ä¸ç›®æ ‡è¯­è¨€ä¸€è‡´æ—¶æ•ˆæœæœ€ä½³
                - è¿‡é«˜æˆ–æç«¯å‚æ•°å¯èƒ½å¯¼è‡´ä¸ç¨³å®š
                - æ‰€æœ‰ç”ŸæˆéŸ³é¢‘åŒ…å«ä¸å¯æ„ŸçŸ¥çš„æ°´å°ä»¥æ”¯æŒè´Ÿè´£ä»»çš„ä½¿ç”¨
                """
            )

    demo.queue(max_size=10)
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True,
        show_api=False,
    )

